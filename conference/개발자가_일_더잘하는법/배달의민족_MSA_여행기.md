# 배달의 민족 MSA 여행기

## 배민 서비스의 역사
- 주문수는 연간 평균 2.3 배 씩 증가 하고 있음
- 일 주문수는 200만건 이상 발생함

### 2015
- 일 주문수 5만건 이하
- MS SQL + PHP, ASP
- 대부분 MS SQL 기반 스토어드 프로시저 방식으로 사용
    - 테이블 700개
    - 프로시저가 4000개  정도 존재함
- DB 장애시 전체 서비스가 장애
- 단일 시스템으로 구성
    - 프론트
    - 회원/인증
    - 리뷰
    - 쿠폰
    - 포인트
    - 정산
    - 주문
    - 결제
    - 주문중계
    - 가게/업주
    - 광고
    - 메뉴
    - 등.. 이 모두 단일 시스템

> DB 하나로 모든 서비스를 했기 때문에 
> 특정 시스템에 (리뷰, 주문 등) 이 리소스를 많이 점유했을 경우 
> 다른 시스템에 까지 영향을 미침..

### 2016
- 일 주문수 10만건 이상
- PHP -> 자바로 변경
    - 인력 수급 문제
    - 대용량 트래픽 안정적인 처리
- MSA 도전 시작
    - 좋은 아키텍쳐라기 보단 MSA로 찢지 않으면, 매일 장애가 나는 사단이 보였다.
- 결제, 주문 중계 독립
- IDC -> AWS 클라우드 인프라로 이전
- 카카오 페이 선착순 할인 이벤트 -> 치도스
    - 앞단에서 버티질 못하니까 주문까지 넘어가질 못함
    - 이벤트 때문에 한달 짜리 이전 계획을 하루만에 다 옮겼음..
- 법적으로 돈과 관련된 것은 클라우드를 사용하면 안됨..

> 각 서비스를 최대한 독립적으로 만들어서, 특정 서비스가 장애 나더라도 최대한 영향이 없도록 만들자
> 서비스 별 특성에 맞게끔 개발 할 수 있다.

- MSA 는 DB 까지 완전히 분리해야 한다!
- 당시에 주문 중계 서비스는 NodeJS 로 개발했다. (단순히 전달만 하는 역할을 하는 서버)
    - 추후에 자바로 변경됨

### 2017
- 일 주문수 20만건 이상
- 대 **장애** 의 시대
- 메뉴, 정산, 가게 목록 시스템 독립
- 배민은 기본적으로 TPS가 몰리는 시간대가 정해져 있음
    - 점심 or 저녁
    - 해당 시간대에 장애가 나서 문제가 발생한다면 (?)
    - 서비스 위기까지 다가 올 수도 있음

### 2018 상반기
- 탈 루비의 시대
- N 광고 폭파 -> 장애대응 TF 창설
    - 가게상세 재개발 (주요 장애 포인트)
- 쿠폰, 포인트 탈루비
- 오프라인 모드 적용 (서버가 장애났을때, 앱에 존재하는 캐시로 동작하도록 처리)
- 시스템 안정성이 가장 중요하다.

`기존 가게 상세`
- 프론트 PHP -> 루비 DB 사용 구조

`신규 가게 상세`
- 가게상세 JAVA -> AWS 다이나모 DB (조회 특화) <-> 루비 DB 1~5분 배치로 동기화

### 2018 하반기
- 주문, 리뷰 시스템 분리
- 가장 복잡한 도메인이라 생각
- 커머스의 꽃

- 주문 시스템 - 당시 하루 100만 데이터
- 가게 /업주 시스템 - 시스템 연관성 가장 높음
- 광고 시스템 - 프로시저 사용량 많음


- 주문서버
    - 배민 주문
    - 라이더스 주문
    - 각각 따로 관리 되고 있었다. 추후 주문서버를 합쳤을때 테이블을 합칠수가 없음..

> 배민 / 라이더스를 수용할수 있는 주문 테이블 자체를 재 설계

`주문 시스템`
- 이벤트 기반 아키텍쳐를 채용
    - 타임아웃 문제
    - 연동 시스템 장애시 데이터 유실 문제 (보정 작업 필요)
- AWS SNS 로 이벤트를 남기고 AWS SQS 로 컨슘하는 구조
    - 시스템 장애시 이벤트 가 남아있기 때문에, 컨슘하기만 하면 금방 복구가 된다.

`가게/업주 시스템`
- 업주 - 광고는 1:1 구조 였으나 이를 개선 해야했음
- 가게/업주 시스템을 손대는 순간 모든 시스템에 영향을 미친다.
- 고성능 조회 - 트래픽이 전파가 된다...

`고려 사항`
- 성능
    - 대용량 트래픽 대응
    - 초당 15,000회 호출
    - 모든 시스템이 대용량 트래픽을 견디기는 힘들다.
- 장애 격리
    - 내부 서비스에 장애가 발생하더라도, 고객 서비스를 유지하고 주문도 가능해야한다.
- 데이터 동기화
    - 데이터가 분산되어 있다.
    
`아키텍쳐`    
- CQRS 도입
    - 핵심 비즈니스 **명령 (Command)** 시스템과 **조회 (Query)** 중심의 서비스를 철저하게 분리한다.
    - Command and Query Responsibility Segregation
- **각 서비스에 필요한 모델** 로 전환해서 가지고 있는다.
- 데이터 변경시 이벤트를 발행 -> 각 시스템에서 컨슘한다.
- 데이터는 언젠가 다 맞추어진다. (1 ~ 3s)
- Zero-Payload 방식을 사용
    - 최소한의 데이터만 발행한다.
    - 가게 데이터가 변경되면 **가게 ID** 값만 이벤트로 발행
    - 각 시스템에서 필요한 데이터가 모두 다르다!!
    - 컨슘한 ID에 해당하는 필요한 데이터 API를 호출
- 최소 데이터 보관 원칙

`데이터 베이스`
- 조회
    - 다이나모, 몽고, 레디스 , ES
- 명령
    - RDB 
    
    
### CQRS Query Model
- 조회에 필요한 모델을 각자 서비스에서 따로 가지고 있는다.
- 데이터 싱크는 이벤트 기반
- 데이터 싱크 장애 대응
    - 큐가 장애가 났을때 어떻게 할것인가 ?
    - 전체 IMPORT API 제공
    - 부분 IMPORT API 제공
        - 최근 업데이트 데이터를 분단위로 부분 제공
- 적극적인 캐시
- 서킷 브레이커
- 비동기 넌 블락 시스템 적용
    - WebFlux

### 정리
- 배민 시스템은 거대한 CQRS
- 성능 중요한 외부시스템과 명령이 많은 내부 시스템으로 분리
- 이벤트 발행을 통한 Eventually Consistency (최종적 일관성)
- 각 시스템은 API 또는 이벤트 방식으로 연동
- 전체 시스템 장애를 택하는것 보다 부분 적인것은 안고간다.
    - 개발자들 레벨에서 해결되는 문제는 아니다.
    - PO, Business 레벨에서도 안고가야 하는 문제
- 필요에 의해서 도입을 해야함
- 섣불리 적용하면 MSA 에 서비스가 발목이 잡힌다.
