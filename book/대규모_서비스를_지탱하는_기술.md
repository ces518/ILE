# 대규모 서비스를 지탱하는 기술

## 대규모 데이터 처리의 어려운 점 - 메모리와 디스크

#### 대규모 데이터를 다룰 때 힘든점은, **메모리 내에서 계산할 수 없다.** 는 점
- 메모리에 올리지 않으면, 기본적으로 디스크를 계속해서 읽어가며 처리 해야한다.
- 데이터 건수가 많아질수록 계산량도 늘어남.
- 디스크 I/O는 매우 느리다.

#### 메모리와 디스크의 속도차이
- 메모리와 디스크는 10의 5승 ~ 10의6승 배 이상 빠르다.
    
#### 디스크가 느린 이유 ?
- 디스크는 동축 상에 '원반'이 쌓여 있다. 원반이 회전하고 있으며, 여기서 데이터를 읽어냄.
- 메모리와 달리 디스크는 **물리적인 동작** 을 수반하고 있음.
- 이 원반 뿐 아니라, 데이터를 읽어내는 '헤드' 도 존재한다.
- 헤드가 붙어 데이터를 읽어 내야 한다.
- 헤드의 이동, 원반의 회전단위 => 각각 4밀리초
- 데이터가 여기저기 분산되어 있을수록, 디스크에서 읽어 들이는 속도는 느려진다.
    
#### OS 레벨 에서의 연구
- OS에서 이를 어느정도 커버하는 작용을 한다.
- OS는 연속된 데이터를 같은 위치에 쌓는데 이는 4KB 단위로 수행한다.
- 비슷한 데이터를 비슷한 위치에 두어 1번 회전으로 읽어들이는 데이터 수를 증가 시켜 이를 완화한다.

#### 전송 속도, 버스의 속도 차이
- 탐색 속도 측면에서 메모리가 디스크에 비해 빠르지만, 이것만의 차이가 아니다.
- 메모리와 디스크 모두 CPU 와 버스로 연결되어 있는데, 이 버스의 전송 속도도 차이가 남.
- 메모리와 CPU는 7.5GB/s, 디스크는 58MB/s 
- SSD로 인해 탐색 속도는 빠르지만, 전송 속도에서 차이가 난다.

#### Linux 단일 호스트의 부하
- 단일 서버의 성능을 충분히 끌어낼 수 있는것을 시작으로 복수 서버의 부하분산이 의미를 가진다.
- **추측하지 말고, 계측하라.**
- 병목 규명작업의 기본 흐름
    - Load Average 확인
    - CPU, I/O 병목 원인 조사

`Load Average 확인`
- 부하 규명의 시작이 되는 지표
- top, uptime 등 명령으로 확인 한다.
- 시스템 전체의 부하상황을 나타내는 지표
- Load Average 는 낮은데, 시스템 전송량이 낮은 경우도 있다.
- 소프트웨어 설정, 오류, 네트워크, 원격 호스트 등을 살펴보라.

`CPU I/O 병목 원인 조사`
- sar, vmstat로 CPU 사용률 과 I/O 대기율 추이 확인
- CPU에 부하가 걸리는 상황 두가지
    - 디스크나 메모리 용량 등 그 밖의 부분에서는 병목이 되지않는 이상적인 상태
    - 프로그램이 폭주하여 CPU에 필요 이상의 부하가 걸리는 경우
- I/O 부하가 높은 경우
    - 프로그램에서 입출력이 많음
    - 스왑이 발생해서 디스크 액세스가 발생하고 있는 상황

> 스왑이 발생하지 않고, 디스크 I/O가 많은 경우 캐시에 필요한 메모리가 부족한 경우도 있다.

- OS 튜닝이란 부하의 원인을 알고 이것을 제거하는 것이다.
- 튜닝의 본질은 하드웨어/소프트웨어가 가지고 있는 본래 성능을 충분히 내도록 문제가 되는 부분을 제거하는것

## 규모조정의 요소

#### 규모조정, 확장성
- 웹 서비스에서는 고가의 하드웨어를 사서 성능을 올리는 **스케일 업 (scale up)** 보다
- 저가이면서 일반적인 성능의 하드웨어를 많이 나열해 전체 성능을 올리는 **스케일 아웃 (scale out)** 전략이 주류이다.

> 하드웨어 성능은 가격과 비례하지 않는다.

#### 규모 조정의 요소 - CPU 부하와 I/O 부하
- 스케일 아웃은 CPU 부하의 확장성을 확보하기는 쉽다.
- 이는 AP 서버에 해당한다 (애플리케이션 서버)
- DB 서버 측면에서는 I/O 부하가 걸린다.

#### 웹 애플리케이션과 부하의 관계
- 기본적으로 AP 서버에는 I/O 부하가 걸리지 않고, DB측에 I/O부하가 걸린다.
- AP 서버는 CPU 부하만 걸리기 때문에 분산이 간단하다.
- 대수를 늘리고, 로드밸런서를 이용해 적절히 분산하기만 하면 되기 때문에 간단하다.
- I/O 부하는 문제가 있다.
- 대수를 늘렸을때, 데이터의 동기화 문제, 쓰기는 간단히 분산할 수가 없다.

#### DB 확장성 확보의 어려움
- DB의 확장성 확보는 상당히 어렵다. 이는 디스크가 느리다는 문제도 한몫을 하고 있다.

#### 두 종류의 부하와 웹 애플리케이션
- 부하는 CPU 부하와 I/O 부하 두가지로 분류 된다.
- 대규모 계산을 하는 프로그램, 이는 I/O는 발생하지 않지만, 계산 속도에 의해 응답 시간이 좌지우지된다.
- 이는 CPU에 부하를 주는 프로그램이다.
- 디스크에 저장된 대량의 데이터를 검색하는 프로그램, 이는 디스크의 읽기속도에 의존한다.
- I/O에 부하를 주는 프로그램이다.

#### 멀티테스킹 OS와 부하
- 여러 OS가 멀티테스킹을 지원하지만, 이는 실제로 매우 짧은 시간간격으로 여러 테스크를 전환해가며, 멀티 테스킹을 실현한다.
- 테스크가 많아질수록,  특정 테스크가 처리중이라면 다른 테스크는 대기를 하게 되는데, '처리를 실행하려고 해도 대기한다' 라는 대기상태가 프로그램 실행 지연으로 나타난다.
- top의 출력 내용에 Load Average (평균 부하) 라는 수치가 포함되어 있다.
- Load Average 가 높을수록 테스크 실행에 대기가 발생하고 있다는 표시이다.

#### Average 가 보고하는 부하의 정체
- 하드웨어는 일정 주기로 CPU에게 인터럽트 신호를 보낸다.
- 주기적으로 보내는 신호라는 점에서 타이머 인터럽트라고 한다.
- 실행 중인 프로세스가 CPU를 얼마나 사용했는지 계산하는 등 시간과 관련된 처리를 한다.
- 커널은 타이머 인터럽트가 발생했을때 테스크 개수를 세어두고, 그 값을 단위 시간으로 계산한것이 Load Average로 보고 된다.

## 대규모 데이터를 다루기 위한 기초지식

#### 대규모 데이터를 다루는 세 가지 급소 - 프로그램 작성 요령
- 요령1. 어떻게 하면 메모리에서 처리를 할 수 있을까 ? 라는 점
    - 메모리에서 처리를 마쳐야하는 이유는 디스크 seek 횟수가 확장성과 성능에 크게 영향을 준다.
- 요령2. 데이터량 증가에 강한 알고리즘을 사용하는것.
    - 레포드 1,000만건이 존재할 때 단순 선형 탐색을 사용하는것 보다 Log Order 알고리즘을 사용하여 탐색 횟수를 줄인다.
- 요령3. 데이터 압축 혹은 검색기술 과 같은 테크닉을 활용한다.
    - 압축하여 데이터량을 줄인다면, 읽어내는 seek 횟수도 적어지게 되므로 I/O 횟수가 줄어든다.
    
> 검색이 중요한 이유는, 확장성 면에서 DB에만 맡겨서 해결할 수 없을 때, 특정 용도에 특화된 검색 엔진등을 만들어 활용하여
> 속도를 확보 한다.

#### 대규모 데이터를 다루기 전 3대 전제 지식 - 프로그램 개발의 한층 아래 기초
- 1. OS 캐시
- 2. 분산을 고려하여 RDBMS 운용시 어떻게 해야만 하는가
- 3. 대규모 환경에서 알고리즘과 데이터 구조를 사용한다는 것은 어떤 것이가

## OS의 캐시 구조

#### OS의 캐시 구조를 알고 애플리케이션 작성하기 - 페이지 캐시
- OS에는 디스크 내의 데이터에 빠르게 액세스할 수 있는 페이지 캐시라 불리는 캐시구조를 가지고 있다.

#### Linux(x86)의 페이징 구조
- OS는 **가상 메모리구조**를 가지고 있으며, 가상 메모리 구조는 논리적인 선형 어드레스를 물리적인 물리 어드레스로 변환하는것.

#### 스왑
- 가상 메모리를 응용한 기능 중 하나로 물리 메모리가 부족할 때 2차 기억장치 (디스크)를 메모리로 간주하여 메모리 부족을 해소하는 원리

#### 가상 메모리 구조
- 가상 메모리가 존재하는 가장 큰 이유는 **물리적인 하드웨어를 OS 레벨에서 추상화** 하기 위해서이다.
- 각 프로세스에서 메모리의 어드레스를 직접 사용하면 여러 문제가 발생한다.
- 프로세스에서 메모리가 필요하다면, OS가 관리중인 메모리에서 비어있는 곳을 사용한다.
- 메모리를 확보할 때에도 디스크를 다룰때와 같이 4KB씩 블록으로 확보해서 프로세스에게 넘기는 이를 **페이지** 라고 한다.

#### Linux의 페이지 캐시 원리
- OS는 확보한 페이지를 메모리상에 계속 확보해두는 기능을 가지고 있따.
- 처리를 마친뒤 불필요하게 되었어도, 이를 해제하지 않고 남겨둠으로 써 다른 프로세스가 재활용할 수 있게 된다.
- 즉, 커널이 한번 할당한 메모리를 해제하지 않고 남겨두는것. 이것이 페이지 캐시의 원리이다.
- 이는 예외인 경우를 제외한 모든 I/O에 작용한다.
- OS를 켜두면 켜둘수록 점점 페이지 캐시가 최적화 되기 때문에 점점 더 빨라진다.

#### VFS
- 디스크 캐시는 페이지 캐시에 의해 제공되지만, 실제 이를 조작하는 디바이스 드라이버와 OS 사이에는 파일시스템이 껴 있다.
- Linux는 ext3, ext2, ext4, xfs 등 몇가지 파일 시스템이 존재하는데 그 하위에 디바이스 드라이버가 있다.
- 이 디바이스 드라이버가 실제 하드디스크를 조작한다.
- 파일 시스템 위에 VFS (Virtual File System) 이라는 추상화 레이어가 있다. 파일 시스템의 인터페이스를 통합하는 것이 역할이다.
- VFS는 페이지 캐시 구조를 지니고 있다.

#### Linux는 페이지 단위로 디스크를 캐싱한다
- OS는 읽어낸 블록 단위만으로 캐싱할 수 있는 범위가 정해진다.
- 디스크 캐싱하는 단위가 페이지 이다.
- 페이지: 가상 메모리의 최소단위

#### LRU
- 메모리 여유분이 1.5GB 존재하고, 파일을 4GB 모두 읽게 될 경우 어떻게 될까 ?
- 구조상 LRU 알고리즘으로 인해 갖아 오래된 것을 파기하고, 가장 새로운것을 남겨 둔다.
- 따라서 DB도 계속 구동시키면 캐시가 점점 최적화 되어, 뒤로 갈수록 부하, I/O가 내려가는 특성을 보인다.

#### 어떻게 캐싱될까? 
- Linux는 파일을 i 노드 번호라고 하는 번호로 식별하며, 해당 파일의 i노드 번호와 해당 파일의 어느 위치부터 시작할지를 나타내는 오프셋.
- 이 두가지 값을 키로 캐싱한다.
- 이 두가지를 키로 하기 때문에 파일 전체가 아닌 파일의 일부를 캐싱할 수 있다.
- 파일이 아무리 크더라도 이 키로부터 해당 페이지를 찾을 때 데이터 구조는 최적화 되어 있으며, **Radix Tree** 라고 한다.

#### 메모리가 비어 있으면 캐싱한다
- Linux는 메모리가 비어있다면 모두 캐싱한다.
- 이는 제한이 없기 때문에 비어있는 캐시 공간에 계속해서 캐싱한다.
- 프로세스에서 메모리를 요청했을 경우, 오래된 캐시를 버리고 프로세스에 메모리를 확보해 준다.

#### 메모리를 늘려서 I/O 부하 줄이기
- 메모리를 늘리면 실제 I/O 부하를 줄일 수 있다.
- 메모리를 늘리면 캐시에 사용 가능한 용량이 늘어나고, 보다 많은 데이터를 캐싱하기 때문에 디스크 I/O 횟수가 줄어든다.

## I/O 부하를 줄이는 방법

#### 캐시를 전제로 한 I/O 줄이는 방법
- 첫 번째 포인트는 데이터 규모에 비해 물리 메모리가 크면 모두 캐싱이 가능하다. 다루고자 하는 데이터의 크기에 주목 할것
- 두 번째는 경제적인 비용과 밸런스를 고려하자. AP 서버는 메모리가 그렇게 많이 필요하지 않으나 DB서버는 많은 메모리를 필요로 한다.

#### 복수 서버로 확장시키기 - 캐시로 해결될 수 없는 규모일 경우
- 데이터를 모두 캐싱할 수 없는 규모일 경우 ?
- 복수서버로 확장 시켜야 한다.
- CPU 분산시에는 단순히 늘린다.
- I/O 분산에는 국소성을 고려해야 한다.

#### 단순히 대수를 늘려서는 확장성을 확보할 수 없다
- 캐시 용량을 늘려야 하는경우 (I/O 분산) 단순히 대수를 늘려서는 해결되지 않는다.
- 애초에 캐시 용량이 부족해서 늘렸지만, 부족한 부분도 그대로 동일하게 늘려가게 된다..
- 캐싱되지 않는 부분은 동일 하다..

## 국소성을 살리는 분산

#### 국소성을 고려한 분산이란 ?
- 캐시 용량을늘리기 위해서는 국소성을 고려한 분산 시켜야 한다.
- 국소성을 고려한 분산이란, 데이터에 대한 엑세스 패턴을 고려해서 분산시키는 것을 국소성을 고려한 분산이라고 한다.

#### 파티셔닝 - 국소성을 고려한 분산
- 국소성을 고려한 분선을 위해 파티셔닝 이라는 기법을 자주 사용한다.
- DB서버를 여러 대로 분할하는 방법
- 분할 방법은 여러가지가 있지만, 간단한 것은 테이블 단위 분할이다.
- 테이블 데이터 분할 방법은 테이블 하나를 여러 작은 테이블로 분할 한다.
- 이런식으로 분할을 하게 되면, 캐싱을 하지 못하는 부분이 사라지게 된다.

#### 요청 패턴을 '섬'으로 분할 - 국소성을 고려한 분산
- 용도별로 시스템을 섬으로 나누는 방법이 있다.
- User-Agent 값을 참조하여, 일반적은 사용자 요청 , 봇의 요청 등을 각각 다른 서버가 처리하도록 만드는 방법
- 일반적인 사용자의 요청은 최상위 페이지나, 인기 페이지에 액세스가 집중되기 때문에 캐싱하기 쉽다.

#### 페이지 캐시를 고려한 운용의 기본 규칙
- OS 기동 직후에 서버를 투입해서는 안된다.
- 캐시가 쌓여 있지않아, 디스크 액세스만 발생하게 되어, 대규모 시스템의 경우 서버가 뻗게 된다.
- 성능평가나, 부하 테스트시에도 캐시가 최적화 된 이후 실시한다.

## 인덱스를 올바르게 운용하기

#### 분산을 고려한 MySQL 운용, 세 가지 포인트
1. OS 캐시 활용
2. 인덱스
3. 확정을 전제로 시스템 설계

#### OS 캐시 활용
- 대량의 데이터를 저장하려는 테이블은 레코드가 가능한 작아지도록 컴팩트하게 설계하자
- 서비스 설계 초기단계 부터 깊게생각할 필요는 없지만, 어느정도 규모가 있는 서비스가 되면 칼럼변경, 스키마 변경에도
그에 상응하는 주의가 필요하다.
- 데이터량 < 물리메모리를 유지하자.

#### 정규화
- 필수항목과 부가 항목을 구분하여 정규화를 하면, 수천만 레코드만큼 용량이 줄어들 수 있다.
- 하지만 경우에 따라 쿼리가 복잡해져 속도가 떨어지는 경우도 있다.
- 모든 설계는 trade-off다.

#### 인덱스의 중요성 - B트리
- 데이터 구조에서 탐색시 기본적으로 트리 구조를 널리 사용한다.
- MySQL 은 기본적으로 B+ 트리 구조를 사용한다.
- 이는 B 트리에서 파생된 데이터 구조이다. (각 노드가 여러 개의 자식을 가질수 있는 다분 트리, 삽입/삭제를 반복해도 치우침이 생기지 않는 평형 트리)

#### 이진트리와 B 트리 비교
- B 트리는 자식 노드의 개수를 지정할 수 있다. 이를 조정함으로 써 4KB 등으로 사이즈를 정할 수 있다.
- 즉 이것이 장점이다.
- OS 는 디스크에서 데이터를 읽을 때 블록 단위로 읽어낸다.
- 이분 트리는 특정 노드를 모아 1블록에 저장하는 작업이 어렵다.
- B 트리는 블록 단위로 저장할 수 있음.
- B+ 트리는 DB에 데이터를 저장하는 좀 더 최적화 된 데이터 구조이다.

#### 인덱스의 효과
- 인덱스 = 색인
- B+ 트리 = 외부 기억장치 탐색시 Seek 횟수를 최소화 하는 트리 구조

#### 인덱스의 작용 - MySQL 의 특성
- 기본적으로 Where, order by, group by 에 지정된 칼럼에 사용된다.
- 복수의 칼럼에 인덱스를 태우고자 할 경우 복합 인덱스를 사용해야 한다.
- MySQL은 한 번의 쿼리에서 하나의 인덱스만 사용한다는 특성을 가지고 있다.

#### 인덱스 작용 확인 - explain 명령
- explain 명령을 사용해 인덱스 작용여부를 확인 가능하다.
- extra 열에서 filesort, temporary 같은 항목이 나올 경우 좋은 쿼리가 아니다.

