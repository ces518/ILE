# 대규모 서비스를 지탱하는 기술

## 대규모 데이터 처리의 어려운 점 - 메모리와 디스크

#### 대규모 데이터를 다룰 때 힘든점은, **메모리 내에서 계산할 수 없다.** 는 점
- 메모리에 올리지 않으면, 기본적으로 디스크를 계속해서 읽어가며 처리 해야한다.
- 데이터 건수가 많아질수록 계산량도 늘어남.
- 디스크 I/O는 매우 느리다.

#### 메모리와 디스크의 속도차이
- 메모리와 디스크는 10의 5승 ~ 10의6승 배 이상 빠르다.
    
#### 디스크가 느린 이유 ?
- 디스크는 동축 상에 '원반'이 쌓여 있다. 원반이 회전하고 있으며, 여기서 데이터를 읽어냄.
- 메모리와 달리 디스크는 **물리적인 동작** 을 수반하고 있음.
- 이 원반 뿐 아니라, 데이터를 읽어내는 '헤드' 도 존재한다.
- 헤드가 붙어 데이터를 읽어 내야 한다.
- 헤드의 이동, 원반의 회전단위 => 각각 4밀리초
- 데이터가 여기저기 분산되어 있을수록, 디스크에서 읽어 들이는 속도는 느려진다.
    
#### OS 레벨 에서의 연구
- OS에서 이를 어느정도 커버하는 작용을 한다.
- OS는 연속된 데이터를 같은 위치에 쌓는데 이는 4KB 단위로 수행한다.
- 비슷한 데이터를 비슷한 위치에 두어 1번 회전으로 읽어들이는 데이터 수를 증가 시켜 이를 완화한다.

#### 전송 속도, 버스의 속도 차이
- 탐색 속도 측면에서 메모리가 디스크에 비해 빠르지만, 이것만의 차이가 아니다.
- 메모리와 디스크 모두 CPU 와 버스로 연결되어 있는데, 이 버스의 전송 속도도 차이가 남.
- 메모리와 CPU는 7.5GB/s, 디스크는 58MB/s 
- SSD로 인해 탐색 속도는 빠르지만, 전송 속도에서 차이가 난다.

#### Linux 단일 호스트의 부하
- 단일 서버의 성능을 충분히 끌어낼 수 있는것을 시작으로 복수 서버의 부하분산이 의미를 가진다.
- **추측하지 말고, 계측하라.**
- 병목 규명작업의 기본 흐름
    - Load Average 확인
    - CPU, I/O 병목 원인 조사

`Load Average 확인`
- 부하 규명의 시작이 되는 지표
- top, uptime 등 명령으로 확인 한다.
- 시스템 전체의 부하상황을 나타내는 지표
- Load Average 는 낮은데, 시스템 전송량이 낮은 경우도 있다.
- 소프트웨어 설정, 오류, 네트워크, 원격 호스트 등을 살펴보라.

`CPU I/O 병목 원인 조사`
- sar, vmstat로 CPU 사용률 과 I/O 대기율 추이 확인
- CPU에 부하가 걸리는 상황 두가지
    - 디스크나 메모리 용량 등 그 밖의 부분에서는 병목이 되지않는 이상적인 상태
    - 프로그램이 폭주하여 CPU에 필요 이상의 부하가 걸리는 경우
- I/O 부하가 높은 경우
    - 프로그램에서 입출력이 많음
    - 스왑이 발생해서 디스크 액세스가 발생하고 있는 상황

> 스왑이 발생하지 않고, 디스크 I/O가 많은 경우 캐시에 필요한 메모리가 부족한 경우도 있다.

- OS 튜닝이란 부하의 원인을 알고 이것을 제거하는 것이다.
- 튜닝의 본질은 하드웨어/소프트웨어가 가지고 있는 본래 성능을 충분히 내도록 문제가 되는 부분을 제거하는것

## 규모조정의 요소

#### 규모조정, 확장성
- 웹 서비스에서는 고가의 하드웨어를 사서 성능을 올리는 **스케일 업 (scale up)** 보다
- 저가이면서 일반적인 성능의 하드웨어를 많이 나열해 전체 성능을 올리는 **스케일 아웃 (scale out)** 전략이 주류이다.

> 하드웨어 성능은 가격과 비례하지 않는다.

#### 규모 조정의 요소 - CPU 부하와 I/O 부하
- 스케일 아웃은 CPU 부하의 확장성을 확보하기는 쉽다.
- 이는 AP 서버에 해당한다 (애플리케이션 서버)
- DB 서버 측면에서는 I/O 부하가 걸린다.

#### 웹 애플리케이션과 부하의 관계
- 기본적으로 AP 서버에는 I/O 부하가 걸리지 않고, DB측에 I/O부하가 걸린다.
- AP 서버는 CPU 부하만 걸리기 때문에 분산이 간단하다.
- 대수를 늘리고, 로드밸런서를 이용해 적절히 분산하기만 하면 되기 때문에 간단하다.
- I/O 부하는 문제가 있다.
- 대수를 늘렸을때, 데이터의 동기화 문제, 쓰기는 간단히 분산할 수가 없다.

#### DB 확장성 확보의 어려움
- DB의 확장성 확보는 상당히 어렵다. 이는 디스크가 느리다는 문제도 한몫을 하고 있다.

#### 두 종류의 부하와 웹 애플리케이션
- 부하는 CPU 부하와 I/O 부하 두가지로 분류 된다.
- 대규모 계산을 하는 프로그램, 이는 I/O는 발생하지 않지만, 계산 속도에 의해 응답 시간이 좌지우지된다.
- 이는 CPU에 부하를 주는 프로그램이다.
- 디스크에 저장된 대량의 데이터를 검색하는 프로그램, 이는 디스크의 읽기속도에 의존한다.
- I/O에 부하를 주는 프로그램이다.

#### 멀티테스킹 OS와 부하
- 여러 OS가 멀티테스킹을 지원하지만, 이는 실제로 매우 짧은 시간간격으로 여러 테스크를 전환해가며, 멀티 테스킹을 실현한다.
- 테스크가 많아질수록,  특정 테스크가 처리중이라면 다른 테스크는 대기를 하게 되는데, '처리를 실행하려고 해도 대기한다' 라는 대기상태가 프로그램 실행 지연으로 나타난다.
- top의 출력 내용에 Load Average (평균 부하) 라는 수치가 포함되어 있다.
- Load Average 가 높을수록 테스크 실행에 대기가 발생하고 있다는 표시이다.

#### Average 가 보고하는 부하의 정체
- 하드웨어는 일정 주기로 CPU에게 인터럽트 신호를 보낸다.
- 주기적으로 보내는 신호라는 점에서 타이머 인터럽트라고 한다.
- 실행 중인 프로세스가 CPU를 얼마나 사용했는지 계산하는 등 시간과 관련된 처리를 한다.
- 커널은 타이머 인터럽트가 발생했을때 테스크 개수를 세어두고, 그 값을 단위 시간으로 계산한것이 Load Average로 보고 된다.

## 대규모 데이터를 다루기 위한 기초지식

#### 대규모 데이터를 다루는 세 가지 급소 - 프로그램 작성 요령
- 요령1. 어떻게 하면 메모리에서 처리를 할 수 있을까 ? 라는 점
    - 메모리에서 처리를 마쳐야하는 이유는 디스크 seek 횟수가 확장성과 성능에 크게 영향을 준다.
- 요령2. 데이터량 증가에 강한 알고리즘을 사용하는것.
    - 레포드 1,000만건이 존재할 때 단순 선형 탐색을 사용하는것 보다 Log Order 알고리즘을 사용하여 탐색 횟수를 줄인다.
- 요령3. 데이터 압축 혹은 검색기술 과 같은 테크닉을 활용한다.
    - 압축하여 데이터량을 줄인다면, 읽어내는 seek 횟수도 적어지게 되므로 I/O 횟수가 줄어든다.
    
> 검색이 중요한 이유는, 확장성 면에서 DB에만 맡겨서 해결할 수 없을 때, 특정 용도에 특화된 검색 엔진등을 만들어 활용하여
> 속도를 확보 한다.

#### 대규모 데이터를 다루기 전 3대 전제 지식 - 프로그램 개발의 한층 아래 기초
- 1. OS 캐시
- 2. 분산을 고려하여 RDBMS 운용시 어떻게 해야만 하는가
- 3. 대규모 환경에서 알고리즘과 데이터 구조를 사용한다는 것은 어떤 것이가

## OS의 캐시 구조

#### OS의 캐시 구조를 알고 애플리케이션 작성하기 - 페이지 캐시
- OS에는 디스크 내의 데이터에 빠르게 액세스할 수 있는 페이지 캐시라 불리는 캐시구조를 가지고 있다.

#### Linux(x86)의 페이징 구조
- OS는 **가상 메모리구조**를 가지고 있으며, 가상 메모리 구조는 논리적인 선형 어드레스를 물리적인 물리 어드레스로 변환하는것.

#### 스왑
- 가상 메모리를 응용한 기능 중 하나로 물리 메모리가 부족할 때 2차 기억장치 (디스크)를 메모리로 간주하여 메모리 부족을 해소하는 원리

#### 가상 메모리 구조
- 가상 메모리가 존재하는 가장 큰 이유는 **물리적인 하드웨어를 OS 레벨에서 추상화** 하기 위해서이다.
- 각 프로세스에서 메모리의 어드레스를 직접 사용하면 여러 문제가 발생한다.
- 프로세스에서 메모리가 필요하다면, OS가 관리중인 메모리에서 비어있는 곳을 사용한다.
- 메모리를 확보할 때에도 디스크를 다룰때와 같이 4KB씩 블록으로 확보해서 프로세스에게 넘기는 이를 **페이지** 라고 한다.

#### Linux의 페이지 캐시 원리
- OS는 확보한 페이지를 메모리상에 계속 확보해두는 기능을 가지고 있따.
- 처리를 마친뒤 불필요하게 되었어도, 이를 해제하지 않고 남겨둠으로 써 다른 프로세스가 재활용할 수 있게 된다.
- 즉, 커널이 한번 할당한 메모리를 해제하지 않고 남겨두는것. 이것이 페이지 캐시의 원리이다.
- 이는 예외인 경우를 제외한 모든 I/O에 작용한다.
- OS를 켜두면 켜둘수록 점점 페이지 캐시가 최적화 되기 때문에 점점 더 빨라진다.

#### VFS
- 디스크 캐시는 페이지 캐시에 의해 제공되지만, 실제 이를 조작하는 디바이스 드라이버와 OS 사이에는 파일시스템이 껴 있다.
- Linux는 ext3, ext2, ext4, xfs 등 몇가지 파일 시스템이 존재하는데 그 하위에 디바이스 드라이버가 있다.
- 이 디바이스 드라이버가 실제 하드디스크를 조작한다.
- 파일 시스템 위에 VFS (Virtual File System) 이라는 추상화 레이어가 있다. 파일 시스템의 인터페이스를 통합하는 것이 역할이다.
- VFS는 페이지 캐시 구조를 지니고 있다.

#### Linux는 페이지 단위로 디스크를 캐싱한다
- OS는 읽어낸 블록 단위만으로 캐싱할 수 있는 범위가 정해진다.
- 디스크 캐싱하는 단위가 페이지 이다.
- 페이지: 가상 메모리의 최소단위

#### LRU
- 메모리 여유분이 1.5GB 존재하고, 파일을 4GB 모두 읽게 될 경우 어떻게 될까 ?
- 구조상 LRU 알고리즘으로 인해 갖아 오래된 것을 파기하고, 가장 새로운것을 남겨 둔다.
- 따라서 DB도 계속 구동시키면 캐시가 점점 최적화 되어, 뒤로 갈수록 부하, I/O가 내려가는 특성을 보인다.

#### 어떻게 캐싱될까? 
- Linux는 파일을 i 노드 번호라고 하는 번호로 식별하며, 해당 파일의 i노드 번호와 해당 파일의 어느 위치부터 시작할지를 나타내는 오프셋.
- 이 두가지 값을 키로 캐싱한다.
- 이 두가지를 키로 하기 때문에 파일 전체가 아닌 파일의 일부를 캐싱할 수 있다.
- 파일이 아무리 크더라도 이 키로부터 해당 페이지를 찾을 때 데이터 구조는 최적화 되어 있으며, **Radix Tree** 라고 한다.

#### 메모리가 비어 있으면 캐싱한다
- Linux는 메모리가 비어있다면 모두 캐싱한다.
- 이는 제한이 없기 때문에 비어있는 캐시 공간에 계속해서 캐싱한다.
- 프로세스에서 메모리를 요청했을 경우, 오래된 캐시를 버리고 프로세스에 메모리를 확보해 준다.

#### 메모리를 늘려서 I/O 부하 줄이기
- 메모리를 늘리면 실제 I/O 부하를 줄일 수 있다.
- 메모리를 늘리면 캐시에 사용 가능한 용량이 늘어나고, 보다 많은 데이터를 캐싱하기 때문에 디스크 I/O 횟수가 줄어든다.

## I/O 부하를 줄이는 방법

#### 캐시를 전제로 한 I/O 줄이는 방법
- 첫 번째 포인트는 데이터 규모에 비해 물리 메모리가 크면 모두 캐싱이 가능하다. 다루고자 하는 데이터의 크기에 주목 할것
- 두 번째는 경제적인 비용과 밸런스를 고려하자. AP 서버는 메모리가 그렇게 많이 필요하지 않으나 DB서버는 많은 메모리를 필요로 한다.

#### 복수 서버로 확장시키기 - 캐시로 해결될 수 없는 규모일 경우
- 데이터를 모두 캐싱할 수 없는 규모일 경우 ?
- 복수서버로 확장 시켜야 한다.
- CPU 분산시에는 단순히 늘린다.
- I/O 분산에는 국소성을 고려해야 한다.

#### 단순히 대수를 늘려서는 확장성을 확보할 수 없다
- 캐시 용량을 늘려야 하는경우 (I/O 분산) 단순히 대수를 늘려서는 해결되지 않는다.
- 애초에 캐시 용량이 부족해서 늘렸지만, 부족한 부분도 그대로 동일하게 늘려가게 된다..
- 캐싱되지 않는 부분은 동일 하다..

## 국소성을 살리는 분산

#### 국소성을 고려한 분산이란 ?
- 캐시 용량을늘리기 위해서는 국소성을 고려한 분산 시켜야 한다.
- 국소성을 고려한 분산이란, 데이터에 대한 엑세스 패턴을 고려해서 분산시키는 것을 국소성을 고려한 분산이라고 한다.

#### 파티셔닝 - 국소성을 고려한 분산
- 국소성을 고려한 분선을 위해 파티셔닝 이라는 기법을 자주 사용한다.
- DB서버를 여러 대로 분할하는 방법
- 분할 방법은 여러가지가 있지만, 간단한 것은 테이블 단위 분할이다.
- 테이블 데이터 분할 방법은 테이블 하나를 여러 작은 테이블로 분할 한다.
- 이런식으로 분할을 하게 되면, 캐싱을 하지 못하는 부분이 사라지게 된다.

#### 요청 패턴을 '섬'으로 분할 - 국소성을 고려한 분산
- 용도별로 시스템을 섬으로 나누는 방법이 있다.
- User-Agent 값을 참조하여, 일반적은 사용자 요청 , 봇의 요청 등을 각각 다른 서버가 처리하도록 만드는 방법
- 일반적인 사용자의 요청은 최상위 페이지나, 인기 페이지에 액세스가 집중되기 때문에 캐싱하기 쉽다.

#### 페이지 캐시를 고려한 운용의 기본 규칙
- OS 기동 직후에 서버를 투입해서는 안된다.
- 캐시가 쌓여 있지않아, 디스크 액세스만 발생하게 되어, 대규모 시스템의 경우 서버가 뻗게 된다.
- 성능평가나, 부하 테스트시에도 캐시가 최적화 된 이후 실시한다.

## 인덱스를 올바르게 운용하기

#### 분산을 고려한 MySQL 운용, 세 가지 포인트
1. OS 캐시 활용
2. 인덱스
3. 확정을 전제로 시스템 설계

#### OS 캐시 활용
- 대량의 데이터를 저장하려는 테이블은 레코드가 가능한 작아지도록 컴팩트하게 설계하자
- 서비스 설계 초기단계 부터 깊게생각할 필요는 없지만, 어느정도 규모가 있는 서비스가 되면 칼럼변경, 스키마 변경에도
그에 상응하는 주의가 필요하다.
- 데이터량 < 물리메모리를 유지하자.

#### 정규화
- 필수항목과 부가 항목을 구분하여 정규화를 하면, 수천만 레코드만큼 용량이 줄어들 수 있다.
- 하지만 경우에 따라 쿼리가 복잡해져 속도가 떨어지는 경우도 있다.
- 모든 설계는 trade-off다.

#### 인덱스의 중요성 - B트리
- 데이터 구조에서 탐색시 기본적으로 트리 구조를 널리 사용한다.
- MySQL 은 기본적으로 B+ 트리 구조를 사용한다.
- 이는 B 트리에서 파생된 데이터 구조이다. (각 노드가 여러 개의 자식을 가질수 있는 다분 트리, 삽입/삭제를 반복해도 치우침이 생기지 않는 평형 트리)

#### 이진트리와 B 트리 비교
- B 트리는 자식 노드의 개수를 지정할 수 있다. 이를 조정함으로 써 4KB 등으로 사이즈를 정할 수 있다.
- 즉 이것이 장점이다.
- OS 는 디스크에서 데이터를 읽을 때 블록 단위로 읽어낸다.
- 이분 트리는 특정 노드를 모아 1블록에 저장하는 작업이 어렵다.
- B 트리는 블록 단위로 저장할 수 있음.
- B+ 트리는 DB에 데이터를 저장하는 좀 더 최적화 된 데이터 구조이다.

#### 인덱스의 효과
- 인덱스 = 색인
- B+ 트리 = 외부 기억장치 탐색시 Seek 횟수를 최소화 하는 트리 구조

#### 인덱스의 작용 - MySQL 의 특성
- 기본적으로 Where, order by, group by 에 지정된 칼럼에 사용된다.
- 복수의 칼럼에 인덱스를 태우고자 할 경우 복합 인덱스를 사용해야 한다.
- MySQL은 한 번의 쿼리에서 하나의 인덱스만 사용한다는 특성을 가지고 있다.

#### 인덱스 작용 확인 - explain 명령
- explain 명령을 사용해 인덱스 작용여부를 확인 가능하다.
- extra 열에서 filesort, temporary 같은 항목이 나올 경우 좋은 쿼리가 아니다.

## MySQL의 분산 - 확장을 전제로 한 시스템 설계

#### MySQL의 레플리케이션 기능
- MySQL에는 레플리케이션 기능이 있다.
- 마스터 - 슬레이브를 지정해 두어, 마스터에서 write 한 내용을 슬레이브가 polling 하여 동일한 내용으로 갱신하는 기능이다.
- 동일한 내용의 서버를 여러대 마련할 수 있다.
- 애플리케이션 구현단에서 select 쿼리만 슬레이브로 보내고, 슬레이브 앞단에 로드밸런서 혹은 MySQL Proxy를 사용해 요청을 분산한다.

#### 마스터/슬레이브 특징 - 참조 계열은 확장하고 갱신 계열은 확장하지 않는다.
- 마스터는 확장할 수 없다.
- 갱신 계열 쿼리가 늘어나게되면 동시성 문제가 발생하게된다.
- 또한 웹 애플리케이션 에서는 쓰는 행위보다 읽는 행위가 90%이상을 차지하기 대문에 마스터가 병목되어 장애가 발생하는 상황은
그리 많지 않다.

#### 갱신/쓰기 계열 확장시 - 테이블 분할, key-value 스토어
- 매우 드물지만 마스터에 엄청난 쓰기 작업이 발생하는 애플리케이션을 개발할 때가 있다.
- 이럴 경우 테이블을 작게 분할해서 쓰기 작업을 분산시키거나, RDBMS를 사용하지 않고, KVS (key-value 스토리지)를 사용하는 방법이 있다.
- key-value 스토리지는 오버헤드가 적고 압도적으로 빠르며 확장하기 쉽다.

> 애플리케이션 측면에서 쓰기 작업 횟수를 줄이는 것은 당연히 고려되어야 한다.

## MySQL의 스케일아웃과 파티셔닝

#### MySQL의 스케일아웃 전략
- 기본적인 스케일 아웃 전략은 데이터가 메모리에 올라가는 크기라면, 메모리에 올리고, 아닐경우 메모리 증설. 인덱스를 제대로 걸자.

#### 파티셔닝에 관한 보충
- 파티셔닝이란 테이블 A와 테이블 B를 서로 다른 서버에 놓아 분산하는 방법
- 파티셔닝은 국소성을 활용한 분산이 가능하기 때문에 캐시가 유효하고 때문에 파티셔닝은 효과적이다.

#### 파티셔닝을 전재로 한 설계
- 파티셔닝을 전제로한 설계가 중요하다.
- JOIN 쿼리를 날리기 위해서는 관련 있는 테이블 A, B를 분할 할 수 없다. (이는 다른 머신으로 나눈다는 의미)
- MySQL은 서로 다른 서버에 있는 테이블을 JOIN하는 기능이 기본적으로 없다. (5.1 에서는 REDERATED 테이블 이용시 가능)
- JOIN 쿼리는 대상이 되는 테이블을 아픙로도 서버 분할하지 않을 것이라 보장할 수 있을때만 사용한다.

#### JOIN 배제 - where ... in 
- INNER JOIN 을 사용하지 않고, 쿼리를 두번에 나눠서 where id in (...) 쿼리를 사용하면 동일한 데이터를 얻을 수 있다.

#### 파티셔닝의 상반관계
- 파티셔닝으로 분산을 할 수 있지만 상반관계가 존재한다.
- 장점은 부하가 내려가고 국소성이 늘어나 캐시효과가 높아진다.
- 단점은 운용이 복잡해진다.
- 고장률이 높아진다.

#### 다중화에 필요한 서버 대수는 몇대 ?
- 다중화에 필요한 서버수는 보통 4대라고 한다.
- 한대는 마스터 3대는 슬레이브로 묶어서 4대를 한 단위로 묶어서 관리한다.
- 그 이유는 마스터가 죽으면 슬레이브 중 한대를 마스터로 승격시키면 되지만
- 슬레이브가 죽을경우 남은 2대중 1대를 내리고 데이터 복제를하여 복구해야하기 때문이다.

#### 애플리케이션의 용도와 서버 대수
- 위의 경우 처럼 분할할 경우 4대였던것이 8대가 되고, 3대로 분할하면 12대가 되어 점점 늘어난다..
- 이럴 경우 반드시 4대가 필요한지 여부를 체크해야한다.
- 일부 기능 정지가 가능한 서비스라면 꼭 4대를 한세트로 유지하지 않아도 된다. (비용 절감)

## 이론과 실전 양쪽과의 싸움

#### 요구되는 기술 요건 규명하기
- RDBMS JOIN을 사용하지 않는것. 과 같은 방법을 배드 노하우일 것이다.
- 나중에 분할될 것을 고려하여 JOIN을 하지말라. 는 '실전적인 노하우' 인 것이다.

#### 대규모 웹 애플리케이션에 있어서 이론과 실전
- 대규모 웹 애플리케이션을 개발, 운용시 이론과 실전 모두를 하지 않으면 안된다.
- 이론과 실전 사이에 균형을 잘 맞춰 실행하는것이 중요하다.

#### 컴퓨터의 문제에 이르는 길을 어떻게 발견할까?
- 이론적으로 배울 뿐만 아니라 응용을 위한 이치를 어느 정도 익혀두는 것도 중요하다.

## 알고리즘과 평가

#### 데이터 규모와 계산량 차이
- 대상 데이터가 클수록 알고리즘이나 데이터 구조 선택이 속도에 영향을 미친다.
- 알고리즘 성능을 측정할 대 최대 탐색 횟수를 계산횟수의 기준이 되는 수로 "계산량" 이라고 한다.

#### 알고리즘이란 ?
- 어떤 값 또는 값의 집합을 입력으로 하고 어떤 값 또는 값의 집합을 출력으로 하는 명확하게 정의된 계산절차이다.

#### 좁은 의미의 알고리즘, 넓은 의미의 알고리즘
- DB에서 레코드를 얻어 적절히 출력하는것 처럼 보통 아무렇지 않게 작성하는 프로그램에 대해서도 "알고리즘이 어떻게 되어있나?"
- 라고 하는 이부분은 도메인 로직 일것이다. 이는 넓은 의미의 알고리즘 이라고 한다.
- 좁은 의미에서의 알고리즘은 정렬 혹은 탐색, 해시와 같은 계산문제의 해법에 대해 논의되고 있는 것이다.

#### 알고리즘을 배우는 의의
- 컴퓨터 자원은 유한하기 때문에, 알고리즘에 대해 배우는것은 중요하다.
- 알고리즘은 디자인 패턴과 마찬가지로 엔지니어에게 공통 언어이다.
- "그 부분은 해시를 사용하면 되잖아" 와 같이 커뮤니케이션을 완료하기 위해 해시가무엇인지 이해해둘 필요가 있다.
- 대규모 데이터를 앞 둔 경우에도 알고리즘이 애플리케이션 성능에 큰 영향을 주기 때문에, 그런 감각을 익히기 위해 알고리즘 학습은 매우 중요하다.

#### 알고리즘의 평가 - 빅오 표기법
- 선형 탐색은 O(n), 이분 탐색은 O(log n) 이라고 한다. 이런 표기법을 빅오 표기법 이라고 한다.
- 입력의 크기가 n 일 때 대략적으로 어느정도 계산이 소요된다는 표기법 이다.
- 특정 상황을 다루는 것이 아닌, 평군 혹은 최대를 평가 한다는것이 핵심이다.

#### 각종 알고리즘의 빅오 표기
- O(1), O(log n) < O(n) < O(n log n) < O(n2) < ... O(2n)
- 우측으로 갈수록 계산량은 많아진다.
- 계산량
    - 시간 복잡도 (실행시간, 단계 횟수)
    - 공간 복잡도 (메모리 사용량)

#### 알고리즘과 데이터 구조
- 알고리즘과 데이터 구조는 뗄수 없는 관계이다.
- 알고리즘에서 자주 사용하는 조작에 맞춰 데이터 구조를 선택할 필요가 있기 때문이다.

#### 계산량과 상수항 - 측정이 중요하다
- 계산량의 빅오 표기법에서는 상수항을 무시한다.
- 상수항이란 해당 알고리즘을 구현하는 중 입력 크기에 의존하지 않지만, 실행하지 않으면 안되는 처리의 일종
- 빅 오 표기법은 알고리즘을 비교할 땐 편리하지만 구현을 포함하여 생각할 때 그게 전부가 아니라는 의미이다.
- 상수항을 줄이기 위해 노력을 기울여야 한다.

#### 구현시 유의해야하는 최적화 이야기
- 처음부터 최적화를 수행하는 것은 대체로 잘못된 방침이다.
- 계산량 O(n2) 인 알고리즘을 대체할 수 있는 O(n log n)이 있다면 후자를 사용하는것이 전자를 최적화하는 것 보다 나을것이다.
- "측정이 중요하다" 는 의미 이다.

#### 알고리즘의 실제 활용 - 측정이 중요하다
- 예측이나 축정이 중요하다.
- 때에 따라서는 명쾌하게 단순한 구현을 시도해보는 것도 좋다.
- 데이터 건수가 적을 경우 최적화가 의미가 없다.

## 하테나 다이어리의 키워드 링크

#### 키워드 링크란 ?
- wiki 처럼 워드에 링크하는 기능이다.
- 기존에는 특정 키워드를 정규식을 사용해서 구현 하였다.
- 하지만 키워드가 많아질수록 시간이 오래 걸리는 문제가 발생함
- 1. 정규표현을 컴파일 처리
- 2. 정규표현에서 패턴 매칭하는 처리
> 위 두가지 모두 캐싱을 이용해서 어느정도 회피가 가능하지만 근본적인 해결방법은 아니었다.

#### 정규표현식 -> Trie - 매칭 구현 변경
- Trie 는 트리구조의 일종인 데이터 구조이다.
- 탐색 대상 데이터의 공통 접두사를 모아서 트리구조를 이루는것이 그특징이다.
- ab, abcde, bc, bab, d 는 ab와 abcde 는 ab라는 공통 접두사를 갖고 있으며 공통 접두사를 정리함으로써 불필요한 것을 배제하는 것이 특징 ㄴ

#### Trie 구조와 패턴 매칭
- Trie 구조를 사전과 비교하며 패턴 매칭을 하면 정규표현식 보다 계산량을 줄일 수 있다.
- Trie 에 입력 문서를 입력 한 뒤, 엣지를 순회 하며 종단이 발견되면 해당 단어가 포함되어 있음을 간주하는 것이다.

#### AC법 - Trie 에 의한 매칭을 좀 더 빠르게
- Aho-Corasick 이라는 방법 이다.
- 사전 내에서 패턴매칭을 수행하는 오토마톤을 구축하고 입력 텍스트에 대해 선형 계산시간을 실현한다.
- 계산량이 사전크기에 의존하지 않는 빠른 방법이다.
- Trie에서 패턴 매칭으로 매칭이 진행되다가, 도중에 실패한 경우 되도아 오는 길의 엣지를 Trie에 추가한 데이터 구조를 사용하는 방법

> 처음 부터 최적의 구현을 사용하는것이 반드시 옳다고는 할 수 없다.

## 하테나 북마크의 기사 분류

#### 기사 분류란 ?
- 과학.학문 혹은 컴퓨터.IT 와 같은 카테고리에 기사 분류

#### 베이지안 필터에 의한 카테고리 판정
- 베이지안 필터를 사용한다. (스팸필터 등에도 응용되고 있음)
- 베이지안 필터는 텍스트 문서 등을 입력으로 받아, 나이브 베이즈 라는 알고리즘을 적용하여 확률적으로 해당 문서가 어느
카테고리에 해당하는지 판정하는 프로그램이다.
- 데이터의 통계 정보로 부터 판정을 수행한다.

#### 기계학습과 대규모 데이터
- 베이지안 필터에는 대량의 정해 데이터를 필요로 하지는 않지만, 기계학습의 테스크에 따라 데이터가 많을수록 정밀도가 향상된다.

#### 대규모 데이터와 웹 서비스
- 구글 검색을 사용하면 잘못된 검색 쿼리에 대해 '이것을 찾으셨나요 ?' 하고 쿼리 추천기능을 보았을 것이다.
- 이는 사용자가 검색한 쿼리로그를 정해 데이터로 사용하여, 잘못입력한경우 이렇게 다시 검색한다 라고 학습된 것이다.

#### 베이지안 필터의 원리
- 베이지안 필터의 핵심은 나이브 베이즈라는 알고리즘 이다.
- 베이즈의 정리라는 공식을 기반으로 하고있는 알고리즘
- 나이브 베이즈에서 카테고리 추정은 문서 D가 주어졌을때 카테고리인 C의 조건부 확률을 구하는 문제이다.
- P(C|D)
- 위 문제를 변형하면 P(C|D) = P(D|C) P(C) / P(D)
- 우변의 각 확률을 구하는 문제로 생각할 수 있음
- 구체적인 확률값이 아닌 각 카테고리로 비교하여, 어떤 확률이 젤 높은지를 나타낸 순위가 중요하다.
- 결과적으로 생각할 값은 두가지로 좁혀진다.
- P(D|C), P(C)
> 카테고리 추정시 이 두가지 값을 학습 데이터의 통계정버로부터 산출하면 된다.

#### 수비 자세와 공격 자세
- 동일한 알고리즘 이라도 대량의 데이터를 빠르게 정렬, 검색, 압축하는 일은 발생하는 문제를 얼마나 잘 맞아들이는가 라는 '수비'
- 기계학습이나 패턴인식 등은 적극적으로 데이터를 응용하고 그 결과에 따라 부가가치를 창출하는 의미로 '공격' 적인 자세로 표현한다.