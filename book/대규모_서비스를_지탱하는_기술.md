# 대규모 서비스를 지탱하는 기술

## 대규모 데이터 처리의 어려운 점 - 메모리와 디스크

#### 대규모 데이터를 다룰 때 힘든점은, **메모리 내에서 계산할 수 없다.** 는 점
- 메모리에 올리지 않으면, 기본적으로 디스크를 계속해서 읽어가며 처리 해야한다.
- 데이터 건수가 많아질수록 계산량도 늘어남.
- 디스크 I/O는 매우 느리다.

#### 메모리와 디스크의 속도차이
- 메모리와 디스크는 10의 5승 ~ 10의6승 배 이상 빠르다.
    
#### 디스크가 느린 이유 ?
- 디스크는 동축 상에 '원반'이 쌓여 있다. 원반이 회전하고 있으며, 여기서 데이터를 읽어냄.
- 메모리와 달리 디스크는 **물리적인 동작** 을 수반하고 있음.
- 이 원반 뿐 아니라, 데이터를 읽어내는 '헤드' 도 존재한다.
- 헤드가 붙어 데이터를 읽어 내야 한다.
- 헤드의 이동, 원반의 회전단위 => 각각 4밀리초
- 데이터가 여기저기 분산되어 있을수록, 디스크에서 읽어 들이는 속도는 느려진다.
    
#### OS 레벨 에서의 연구
- OS에서 이를 어느정도 커버하는 작용을 한다.
- OS는 연속된 데이터를 같은 위치에 쌓는데 이는 4KB 단위로 수행한다.
- 비슷한 데이터를 비슷한 위치에 두어 1번 회전으로 읽어들이는 데이터 수를 증가 시켜 이를 완화한다.

#### 전송 속도, 버스의 속도 차이
- 탐색 속도 측면에서 메모리가 디스크에 비해 빠르지만, 이것만의 차이가 아니다.
- 메모리와 디스크 모두 CPU 와 버스로 연결되어 있는데, 이 버스의 전송 속도도 차이가 남.
- 메모리와 CPU는 7.5GB/s, 디스크는 58MB/s 
- SSD로 인해 탐색 속도는 빠르지만, 전송 속도에서 차이가 난다.

#### Linux 단일 호스트의 부하
- 단일 서버의 성능을 충분히 끌어낼 수 있는것을 시작으로 복수 서버의 부하분산이 의미를 가진다.
- **추측하지 말고, 계측하라.**
- 병목 규명작업의 기본 흐름
    - Load Average 확인
    - CPU, I/O 병목 원인 조사

`Load Average 확인`
- 부하 규명의 시작이 되는 지표
- top, uptime 등 명령으로 확인 한다.
- 시스템 전체의 부하상황을 나타내는 지표
- Load Average 는 낮은데, 시스템 전송량이 낮은 경우도 있다.
- 소프트웨어 설정, 오류, 네트워크, 원격 호스트 등을 살펴보라.

`CPU I/O 병목 원인 조사`
- sar, vmstat로 CPU 사용률 과 I/O 대기율 추이 확인
- CPU에 부하가 걸리는 상황 두가지
    - 디스크나 메모리 용량 등 그 밖의 부분에서는 병목이 되지않는 이상적인 상태
    - 프로그램이 폭주하여 CPU에 필요 이상의 부하가 걸리는 경우
- I/O 부하가 높은 경우
    - 프로그램에서 입출력이 많음
    - 스왑이 발생해서 디스크 액세스가 발생하고 있는 상황

> 스왑이 발생하지 않고, 디스크 I/O가 많은 경우 캐시에 필요한 메모리가 부족한 경우도 있다.

- OS 튜닝이란 부하의 원인을 알고 이것을 제거하는 것이다.
- 튜닝의 본질은 하드웨어/소프트웨어가 가지고 있는 본래 성능을 충분히 내도록 문제가 되는 부분을 제거하는것